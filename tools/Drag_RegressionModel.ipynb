{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Drag Regression Model ##\n",
    "\n",
    "This script runs a pipeline to load data, format data, train the neural network, evaluate it's accuracy, and save the model.\n",
    "\n",
    "This drag takes into account the specfic speed, draft, and length of the vessel in its prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModified Michell CW calcs to condsider:\\n\\nMCW.CalcDrag(U,LOA,WL,[CW], T, SA, rho=1025)\\n\\n\\nMCW.Calc_Cf(U,WL)\\n\\nMCW.interp_CW(Fn=Fn,T=T,CW=CW)\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import tools\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "'''\n",
    "import multiprocessing as mp\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import sklearn.preprocessing as PP\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/ada/Documents/HullParameterization')\n",
    "\n",
    "from HullParameterization import Hull_Parameterization as HP\n",
    "\n",
    "import ModifiedMichellCw as MCW\n",
    "\n",
    "rho = 1025 #(kg/m^3) saltwater density  \n",
    "\n",
    "\"\"\"\n",
    "Modified Michell CW calcs to condsider:\n",
    "\n",
    "MCW.CalcDrag(U,LOA,WL,[CW], T, SA, rho=1025)\n",
    "\n",
    "\n",
    "MCW.Calc_Cf(U,WL)\n",
    "\n",
    "MCW.interp_CW(Fn=Fn,T=T,CW=CW)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPU Multithreading\n",
    "\n",
    "def run_MAP_multiprocessing(func, argument_list, chunksize = None, show_prog = True):\n",
    "    \"\"\"Run function in parallel\n",
    "    Parameters\n",
    "    ----------\n",
    "    func:          function\n",
    "                    Python function to run in parallel.\n",
    "    argument_list: list [N]\n",
    "                    List of arguments to be passed to the function in each parallel run.\n",
    "            \n",
    "    show_prog:     boolean\n",
    "                    If true a progress bas will be displayed to show progress. Default: True.\n",
    "    Returns\n",
    "    -------\n",
    "    output:        list [N,]\n",
    "                    outputs of the function for the given arguments.\n",
    "    \"\"\"\n",
    "    #Reserve 2 threads for other Tasks\n",
    "    #pool = mp.Pool(processes=mp.cpu_count()-2)\n",
    "    \n",
    "    if show_prog:            \n",
    "        result_list_tqdm = []\n",
    "        for result in tqdm(pool.map(func=func, iterable=argument_list,chunksize=chunksize), total=len(argument_list),position=0, leave=True):\n",
    "            result_list_tqdm.append(result)\n",
    "    else:\n",
    "        result_list_tqdm = []\n",
    "        for result in pool.map(func=func, iterable=argument_list,chunksize=chunksize):\n",
    "            result_list_tqdm.append(result)\n",
    "\n",
    "    return result_list_tqdm\n",
    "\n",
    "\n",
    "def run_IMAP_multiprocessing(func, argument_list, chunksize = None, show_prog = True):\n",
    "    \"\"\"Run function in parallel\n",
    "    Parameters\n",
    "    ----------\n",
    "    func:          function\n",
    "                    Python function to run in parallel.\n",
    "    argument_list: list [N]\n",
    "                    List of arguments to be passed to the function in each parallel run.\n",
    "            \n",
    "    show_prog:     boolean\n",
    "                    If true a progress bas will be displayed to show progress. Default: True.\n",
    "    Returns\n",
    "    -------\n",
    "    output:        list [N,]\n",
    "                    outputs of the function for the given arguments.\n",
    "    \"\"\"\n",
    "    #Reserve 2 threads for other Tasks\n",
    "    #pool = mp.Pool(processes=mp.cpu_count()-2)\n",
    "    \n",
    "    if show_prog:            \n",
    "        result_list_tqdm = []\n",
    "        for result in tqdm(pool.imap(func=func, iterable=argument_list,chunksize=chunksize), total=len(argument_list),position=0, leave=True):\n",
    "            result_list_tqdm.append(result)\n",
    "    else:\n",
    "        result_list_tqdm = []\n",
    "        for result in pool.imap(func=func, iterable=argument_list,chunksize=chunksize):\n",
    "            result_list_tqdm.append(result)\n",
    "\n",
    "    return result_list_tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Format the Training Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 2)\n"
     ]
    }
   ],
   "source": [
    "#Load XLimits\n",
    "\n",
    "X_LIMITS = np.load('./data/X_LIMITS.npy')\n",
    "\n",
    "print(X_LIMITS.shape)\n",
    "\n",
    "#Load in Volume Prediction for Now\n",
    "DesVecName = 'Input_Vectors.csv'\n",
    "YName = 'GeometricMeasures/Volume.csv'\n",
    "CwName = 'GeometricMeasures/Cw.csv'\n",
    "DS_path = '/home/ada/Documents//Hull_DataSet/'\n",
    "\n",
    "folder_roots = ['Constrained_Randomized_Set_1', \n",
    "                'Constrained_Randomized_Set_2',\n",
    "                'Constrained_Randomized_Set_3',\n",
    "                'Diffusion_Aug_Set_1',\n",
    "                'Diffusion_Aug_Set_2']\n",
    "DesVec = []\n",
    "Cw = []\n",
    "\n",
    "for i in range(0,len(folder_roots)):\n",
    "    path = DS_path + folder_roots[i] + '/'    \n",
    "    #Location of Design Vectors\n",
    "    with open(path + DesVecName) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for count, row in enumerate(reader):\n",
    "            if count != 0:\n",
    "                DesVec.append(row)\n",
    "\n",
    "    #Location of Cw Vectors\n",
    "    with open(path + CwName) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for count, row in enumerate(reader):\n",
    "            if count != 0:\n",
    "                Cw.append(row)\n",
    "'''\n",
    "    #Location of Vol Vectors\n",
    "    with open(path + YName) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for count, row in enumerate(reader):\n",
    "            if count != 0:\n",
    "                YVec.append(row)\n",
    "            else:\n",
    "                labels = np.array(row)\n",
    "'''\n",
    "DesVec = np.array(DesVec)\n",
    "DesVec = DesVec.astype(np.float32())\n",
    "\n",
    "np.save('DesVec_82k.npy',DesVec)\n",
    "\n",
    "Cw = np.array(Cw)\n",
    "Cw = Cw.astype(np.float32())\n",
    "\n",
    "np.save('Cw_82k.npy',Cw)\n",
    "\n",
    "#YVec = np.array(YVec)\n",
    "#YVec = YVec.astype(np.float32())\n",
    "\n",
    "#Normalize Volume to LogScale\n",
    "#Y_log = np.log10(YVec)\n",
    "\n",
    "def Performance_Metric(X):\n",
    "    hull = HP(X)\n",
    "    Z = hull.Calc_VolumeProperties(101,1000)\n",
    "    \n",
    "    return np.divide(hull.Volumes,X[0]**3.0)\n",
    "\n",
    "def Calc_GeometricProperties(x):\n",
    "    '''\n",
    "    This function takes in a Ship Design Vector and calculates the volumetric properties of the hull \n",
    "    \n",
    "    It returns the values for:\n",
    "    \n",
    "    Z / L             -> nondimensialized vector for the height at which each value was measured\n",
    "    Volume / L^3\n",
    "    Area of Waterplane / L^2\n",
    "    Longitudinal Centers of Buoyancy/L\n",
    "    Vertical Center of Buoyancy / L\n",
    "    Longitudinal Center of Flotation / L\n",
    "    Ixx / L^4\n",
    "    Iyy / L^4\n",
    "    \n",
    "    where L = LOA of the design vector ( x[0])\n",
    "    \n",
    "    This function is written to be paralellized   \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    hull = HP(x)\n",
    "       \n",
    "    Z = hull.Calc_VolumeProperties(NUM_WL = 101, PointsPerWL = 1000)\n",
    "    \n",
    "    L = x[0]\n",
    "    \n",
    "    z = np.divide(Z,L)\n",
    "    Vol = np.divide(hull.Volumes,L**3.0)\n",
    "    WP = np.divide(hull.Areas_WP,L**2.0)\n",
    "    LCF = np.divide(hull.LCFs,L)\n",
    "    Ixx = np.divide(hull.I_WP[:,0],L**4.0)\n",
    "    Iyy = np.divide(hull.I_WP[:,1],L**4.0)\n",
    "    LCB = np.divide(hull.VolumeCentroids[:,0],L)\n",
    "    VCB = np.divide(hull.VolumeCentroids[:,0],L)\n",
    "    WSA = np.divide(hull.Area_WS,L**2.0)\n",
    "    WL = np.divide(hull.WL_Lengths,L)\n",
    "    \n",
    "    \n",
    "    return np.concatenate((z,Vol,WP,LCB,VCB,LCF,Ixx,Iyy,WSA,WL),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets clean up X\n",
    "\n",
    "idx_BBFactors = [33,34,35,36,37]\n",
    "idx_BB = 31\n",
    "\n",
    "idx_SBFactors = [38,39,40,41,42,43,44]\n",
    "idx_SB = 32\n",
    "\n",
    "for i in range(0,len(DesVec)):\n",
    "    \n",
    "    DesVec[i,idx_BBFactors] = DesVec[i,idx_BB] * DesVec[i,idx_BBFactors] \n",
    "    DesVec[i,idx_SBFactors] = DesVec[i,idx_SB] * DesVec[i,idx_SBFactors]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Length Ratios...\n",
      "Threads: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82168/82168 [05:39<00:00, 242.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Ratios Calculations Complete!\n",
      "(82168, 1010)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "#Compute Length Ratios:\n",
    "\n",
    "#Run multiprocessing to calculate the length ratios\n",
    "def Calc_LengthRatios(x):\n",
    "    hull = HP(x)\n",
    "    Loa_wBulb = hull.Calc_LOA_wBulb()/x[0]\n",
    "    Beam_mid = hull.Calc_Max_Beam_midship()/x[0]\n",
    "    hull.PCMeasurement = hull.gen_pointCloud(NUM_WL = 101, PointsPerWL = 1000, bit_GridOrList = 1, Z =  np.linspace(0.00001,hull.Dd, num=101))\n",
    "    Beam_pc   = hull.Calc_Max_Beam_PC()/x[0]\n",
    "    return [Loa_wBulb,Beam_mid,Beam_pc]\n",
    "\n",
    "CHUNKS = 128\n",
    "print('Calculating Length Ratios...')\n",
    "print('Threads: ' + str(mp.cpu_count()))\n",
    "pool = mp.Pool(processes=mp.cpu_count()-2)\n",
    "Len_Ratios = run_IMAP_multiprocessing(Calc_LengthRatios, DesVec,chunksize=CHUNKS,show_prog=True)\n",
    "Len_Ratios = np.array(Len_Ratios)\n",
    "np.save('Length_Ratios.npy',Len_Ratios)\n",
    "print('Length Ratios Calculations Complete!')\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "Y = np.load('GeometricMeasures.npy')\n",
    "print(Y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Normalize the Design Vectors: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Normalizer:\n",
    "    def __init__(self, X_LL_Scaled, X_UL_Scaled,datalength):\n",
    "        \n",
    "        self.normalizer = PP.QuantileTransformer(\n",
    "            output_distribution='normal',\n",
    "            n_quantiles=max(min(datalength // 30, 1000), 10),\n",
    "            subsample=int(1e9)\n",
    "            )\n",
    "        \n",
    "        self.X_LL_Scaled = X_LL_Scaled\n",
    "        self.X_UL_Scaled = X_UL_Scaled\n",
    "        \n",
    "        self.X_LL_norm = np.zeros((1,len(X_LL_Scaled)))\n",
    "        self.X_UL_norm = np.zeros((1,len(X_LL_Scaled)))\n",
    "        \n",
    "        self.X_mean = np.zeros((1,len(X_LL_Scaled)))\n",
    "        self.X_std = np.zeros((1,len(X_LL_Scaled)))\n",
    "        \n",
    "    def fit_Data(self,X):\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = 2.0*(X-self.X_LL_Scaled)/(self.X_UL_Scaled- self.X_LL_Scaled) - 1.0\n",
    "        \n",
    "        self.normalizer.fit(x)\n",
    "        x = self.normalizer.transform(x) # Scale Dataset between \n",
    "        #x = (X-self.X_LL_Scaled)/(self.X_UL_Scaled- self.X_LL_Scaled)\n",
    "        \n",
    "\n",
    "        return x\n",
    "    \n",
    "    def transform_Data(self,X):\n",
    "        x = 2.0*(X-self.X_LL_Scaled)/(self.X_UL_Scaled- self.X_LL_Scaled) - 1.0\n",
    "        \n",
    "        \n",
    "        x = self.normalizer.transform(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "    def scale_X(self,z):\n",
    "        #rescales data\n",
    "        z = self.normalizer.inverse_transform(z)\n",
    "        scaled = (z + 1.0) * 0.5 * (self.X_UL_Scaled - self.X_LL_Scaled) + self.X_LL_Scaled\n",
    "        #scaled = z* (self.X_UL_Scaled - self.X_LL_Scaled) + self.X_LL_Scaled\n",
    "\n",
    "        '''\n",
    "        x = self.normalizer.inverse_transform(x)\n",
    "        \n",
    "        #scaled = x* (self.X_UL_norm - self.X_LL_norm) + self.X_LL_norm\n",
    "        '''\n",
    "        #z = (z + 1.0) * 0.5 * (8.0) + 4.0\n",
    "       \n",
    "        #scaled = z*self.X_std + self.X_mean\n",
    "        #scaled = self.normalizer.inverse_transform(scaled)\n",
    "        return scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Regression Model Class ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  \n",
    "\n",
    "\n",
    "\n",
    "class Drag_Regression_ResNet(torch.nn.Module):\n",
    "    def __init__(self, Reg_Dict):\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        self.xdim = Reg_Dict['xdim']+3 # Add 3 Draft, Velocity (Froude Number), and Length scale (LOA)\n",
    "        self.ydim = 1\n",
    "        self.tdim = Reg_Dict['tdim']\n",
    "        self.net = Reg_Dict['net']\n",
    "        \n",
    "        self.fc = nn.ModuleList()\n",
    "        \n",
    "        self.fc.append(self.LinLayer(self.tdim,self.net[0]))\n",
    "        \n",
    "        for i in range(1, len(self.net)):\n",
    "            self.fc.append(self.LinLayer(self.net[i-1],self.net[i]))\n",
    "            \n",
    "        self.fc.append(self.LinLayer(self.net[-1], self.tdim))\n",
    "        '''\n",
    "        #self.tc = nn.ModuleList()\n",
    "\n",
    "        #for i in range(0, len(self.net)):\n",
    "            self.tc.append(self.LinLayer(self.tdim,self.net[i]))\n",
    "        self.tc.append(self.LinLayer(self.tdim, self.tdim))\n",
    "        '''\n",
    "        self.finalLayer = nn.Sequential(nn.Linear(self.tdim, self.ydim))\n",
    "        \n",
    "    \n",
    "        self.X_embed = nn.Linear(self.xdim, self.tdim)\n",
    "        #self.T_embed = nn.Linear(self.ydim, self.tdim)\n",
    "       \n",
    "        \n",
    "    def LinLayer(self, dimi, dimo):\n",
    "        \n",
    "        return nn.Sequential(nn.Linear(dimi,dimo),\n",
    "                             nn.SiLU(),\n",
    "                             nn.LayerNorm(dimo),\n",
    "                             nn.Dropout(p=0.1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.X_embed(x)\n",
    "    \n",
    "        res_x = x\n",
    "\n",
    "        for i in range(0,len(self.fc)):\n",
    "            x = self.fc[i](x)\n",
    "        \n",
    "        x = torch.add(x,res_x)\n",
    "        x = self.finalLayer(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Training Environment ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Drag_Regressor_Training_Env:\n",
    "    def __init__(self, Drag_Reg_Dict, DesVec, CwVec, WL, WSA, Fn_range = [0.1,0.45], T_range = [.25,.67], LOA_range = [3,450]):\n",
    "\n",
    "        self.Reg_Dict = Drag_Reg_Dict\n",
    "        self.DesVec = DesVec\n",
    "\n",
    "        self.QT = Data_Normalizer(X_LIMITS[:,0],X_LIMITS[:,1],len(DesVec))\n",
    "        \n",
    "        self.X = np.copy(DesVec[:,1:])\n",
    "\n",
    "        # Quantile Transform X:\n",
    "        self.X = self.QT.fit_Data(self.X)\n",
    "\n",
    "        self.CwVec = CwVec\n",
    "        self.WL = WL\n",
    "        self.WSA = WSA  \n",
    "        self.Fn_range = Fn_range   \n",
    "        self.T_range = T_range\n",
    "        self.LOA_range = LOA_range\n",
    "        \n",
    "        self.num_WL_Steps = 101\n",
    "        self.T_vec = np.linspace(0,1,self.num_WL_Steps)\n",
    "        \n",
    "      \n",
    "        self.model = Drag_Regression_ResNet(self.Reg_Dict)\n",
    "        self.device =torch.device(self.Reg_Dict['device_name'])\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.data_length = len(self.X)\n",
    "        self.batch_size = self.Reg_Dict['batch_size']\n",
    "        self.num_epochs = self.Reg_Dict['Training_Epochs']\n",
    "        \n",
    "        lr = self.Reg_Dict['lr']\n",
    "        self.init_lr = lr\n",
    "        weight_decay = self.Reg_Dict['weight_decay']\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "    '''\n",
    "    ==============================================================================\n",
    "    Base Regression Training Functions\n",
    "    ==============================================================================\n",
    "    '''\n",
    "    def batch_CT(self,x, A, batch_size = None):\n",
    "        '''\n",
    "        This function takes in a batch of design vectors and outputs the corresponding CT values\n",
    "        '''\n",
    "        if batch_size == None:\n",
    "            batch_size = self.batch_size\n",
    "        \n",
    "         #Random Log Scale LOA \n",
    "        log10_LOA = np.random.uniform(np.log10(self.LOA_range[0]), np.log10(self.LOA_range[1]),(batch_size,))\n",
    "        LOA = 10**log10_LOA       \n",
    "\n",
    "        #Random Waterline\n",
    "\n",
    "        t = np.random.uniform(self.T_range[0], self.T_range[1], (batch_size,))\n",
    "        t_tens = torch.tensor(t[:,np.newaxis]).float().to(self.device)\n",
    "\n",
    "        #Random Froude Number\n",
    "        Fn = np.random.uniform(self.Fn_range[0],self.Fn_range[1],(batch_size,))\n",
    "\n",
    "        WL = np.array([HP.interp(self.WL[A[i]],self.T_vec,t[i]) for i in range(0,len(t))]) #Non-dimensionalized Waterline Length    \n",
    "\n",
    "        U = Fn * np.sqrt(9.81*LOA*WL)\n",
    "\n",
    "        WSA = np.array([HP.interp(self.WSA[A[i]],self.T_vec,t[i]) for i in range(0,len(t))]) #Non-dimensionalized Wetted Surface Area\n",
    "\n",
    "        #Interpolate Cw and calc Cf\n",
    "        CW = np.zeros((batch_size,))\n",
    "        CF = np.zeros((batch_size,))   \n",
    "\n",
    "        for i in range(0,batch_size):\n",
    "            CW[i] = MCW.interp_CW(Fn[i], t[i], self.CwVec[A[i]])\n",
    "            CF[i] = MCW.Calc_Cf(U[i],LOA[i]*WL[i])*WSA[i] #CF = Rf/(0.5*rho*U^2*WSA) * WSA/LOA**2 = Cf * WSA/LOA**2\n",
    "        \n",
    "        #Put CT on a log scale and Batch\n",
    "        CT = np.log10(CW + CF)\n",
    "        \n",
    "        y_batch = torch.tensor(CT[:,np.newaxis]).float().to(self.device)\n",
    "\n",
    "        #Batch x\n",
    "        log10_LOA = torch.tensor(log10_LOA[:,np.newaxis]).float().to(self.device)\n",
    "        Fn = torch.tensor(Fn[:,np.newaxis]).float().to(self.device)\n",
    "        \n",
    "        x_batch = torch.cat((x,t_tens,Fn,log10_LOA),dim=1)\n",
    "        \n",
    "        return x_batch,y_batch\n",
    "    \n",
    "    def run_regressor_step(self,x,y):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        ones = torch.ones_like(y)\n",
    "\n",
    "        predicted_y = self.model(x)\n",
    "        \n",
    "        loss =  F.mse_loss(predicted_y, y)\n",
    "        #print(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss  \n",
    "    \n",
    "    def run_train_regressors_loop(self,batches_per_epoch=64, subsample_per_batch = 64):\n",
    "            \n",
    "            num_batches = self.data_length // self.batch_size\n",
    "        \n",
    "            batches_per_epoch = min(num_batches,batches_per_epoch)\n",
    "\n",
    "            \n",
    "            \n",
    "            print('Regressor Model Training...')\n",
    "\n",
    "            for i in tqdm(range(0,self.num_epochs)):\n",
    "\n",
    "                for j in range(0,batches_per_epoch):\n",
    "                    \n",
    "                    A = np.random.randint(0,self.data_length,self.batch_size)\n",
    "                    x = torch.tensor(self.X[A]).float().to(self.device) \n",
    "\n",
    "                \n",
    "                    for k in range(0,subsample_per_batch):\n",
    "                        x_batch,y_batch = self.batch_CT(x,A)\n",
    "                       \n",
    "                        loss = self.run_regressor_step(x_batch,y_batch)\n",
    "                if i % 1000 == 0:\n",
    "\n",
    "                    print('Epoch: ' + str(i) + ' Loss: ' + str(loss))   \n",
    "                    \n",
    "        \n",
    "            print('Regression Model Training Complete!')\n",
    "\n",
    "            self.model.eval()\n",
    "            eval_size = 10000\n",
    "\n",
    "            A = np.random.randint(0,self.data_length,eval_size)\n",
    "            x_eval = torch.tensor(self.X[A]).float().to(self.device)\n",
    "\n",
    "            x_eval,Y_calc = self.batch_CT(x_eval,A,eval_size)\n",
    "\n",
    "            Y_calc = Y_calc.to(torch.device('cpu')).detach().numpy()\n",
    "\n",
    "            Y_pred = self.model(x_eval)\n",
    "            Y_pred = Y_pred.to(torch.device('cpu')).detach().numpy() \n",
    "\n",
    "            Rsq = r2_score(Y_calc, Y_pred)\n",
    "            print(\"R2 score of Y:\" + str(Rsq))\n",
    "\n",
    "\n",
    "    # SAVE FUNCTIONS\n",
    "        \n",
    "    def load_trained_model(self):\n",
    "        label = self.Reg_Dict['Model_Path']\n",
    "        self.model.load_state_dict(torch.load(label))\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "    \n",
    "    def Save_model(self,PATH):\n",
    "        '''\n",
    "        PATH is the path to the folder to store this in, including '/' at the end\n",
    "       \n",
    "        '''\n",
    "\n",
    "        torch.save(self.model.state_dict(), PATH + self.Reg_Dict['Model_Label']+'.pth')\n",
    "        \n",
    "        JSON = json.dumps(self.Reg_Dict)\n",
    "        f = open(PATH + self.Reg_Dict['Model_Label'] + '_Dict.json', 'w')\n",
    "        f.write(JSON)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Model Training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size:  1343489\n",
      "Regressor Model Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/50000 [00:00<7:46:06,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: tensor(0.1898, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1001/50000 [09:15<7:31:31,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 Loss: tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2001/50000 [18:36<7:25:57,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 Loss: tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3001/50000 [27:56<7:10:53,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3000 Loss: tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4001/50000 [37:11<7:08:52,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000 Loss: tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5001/50000 [46:29<7:05:18,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000 Loss: tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6001/50000 [55:45<6:48:25,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6000 Loss: tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7001/50000 [1:05:03<6:41:36,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7000 Loss: tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8001/50000 [1:14:21<6:29:49,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8000 Loss: tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9001/50000 [1:23:40<6:25:58,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9000 Loss: tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10001/50000 [1:32:59<6:09:31,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 Loss: tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11001/50000 [1:42:17<6:06:38,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11000 Loss: tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12001/50000 [1:51:36<5:56:25,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12000 Loss: tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13001/50000 [2:00:55<5:44:08,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13000 Loss: tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14001/50000 [2:10:14<5:39:55,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14000 Loss: tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15001/50000 [2:19:35<5:25:46,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15000 Loss: tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16001/50000 [2:28:54<5:18:19,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16000 Loss: tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17001/50000 [2:38:14<5:12:31,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17000 Loss: tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18001/50000 [2:47:35<4:59:58,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18000 Loss: tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19001/50000 [2:56:54<4:49:44,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19000 Loss: tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20001/50000 [3:06:11<4:48:11,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20000 Loss: tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21001/50000 [3:15:30<4:31:28,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21000 Loss: tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22001/50000 [3:24:48<4:22:30,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22000 Loss: tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23001/50000 [3:34:06<4:15:38,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23000 Loss: tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24001/50000 [3:43:23<4:00:10,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24000 Loss: tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25001/50000 [3:52:39<3:46:45,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25000 Loss: tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26001/50000 [4:01:55<3:43:17,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26000 Loss: tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27001/50000 [4:11:10<3:32:34,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27000 Loss: tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28001/50000 [4:20:27<3:27:12,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28000 Loss: tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29001/50000 [4:29:43<3:14:09,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29000 Loss: tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30001/50000 [4:38:56<3:02:13,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30000 Loss: tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31001/50000 [4:48:11<2:56:04,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31000 Loss: tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32001/50000 [4:57:29<2:45:54,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32000 Loss: tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33001/50000 [5:06:46<2:35:39,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33000 Loss: tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34001/50000 [5:16:01<2:27:54,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34000 Loss: tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35001/50000 [5:25:16<2:19:20,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35000 Loss: tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36001/50000 [5:34:32<2:11:17,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36000 Loss: tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37001/50000 [5:43:48<2:00:23,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37000 Loss: tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38001/50000 [5:53:03<1:51:07,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38000 Loss: tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39001/50000 [6:02:18<1:41:56,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39000 Loss: tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40001/50000 [6:11:36<1:32:33,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40000 Loss: tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41001/50000 [6:20:51<1:23:09,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41000 Loss: tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42001/50000 [6:30:07<1:13:11,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42000 Loss: tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43001/50000 [6:39:22<1:03:42,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43000 Loss: tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44001/50000 [6:48:38<54:59,  1.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44000 Loss: tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45001/50000 [6:57:52<46:51,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45000 Loss: tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46001/50000 [7:07:09<36:39,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46000 Loss: tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47001/50000 [7:16:25<27:55,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47000 Loss: tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48001/50000 [7:25:39<18:33,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48000 Loss: tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49001/50000 [7:34:56<09:17,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49000 Loss: tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [7:44:12<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Model Training Complete!\n",
      "R2 score of Y:0.997389711775577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Regression model Dict\n",
    "nodes = 512\n",
    "\n",
    "Reg_Dict = {\n",
    "        'xdim' : len(DesVec[0])-1,              # Dimension of parametric design vector\n",
    "        'ydim': 1,                              # trains regression model for each objective\n",
    "        'tdim': nodes,                            # dimension of latent variable\n",
    "        'net': [nodes,nodes,nodes,nodes],                       # network architecture        \n",
    "        'Training_Epochs': 50000,  #30000             # number of training epochs\n",
    "        'batch_size': 1024,                       # batch size\n",
    "        'Model_Label': 'Regressor_CT',         # labels for regressors\n",
    "                    \n",
    "        'lr' : 0.001,                          # learning rate\n",
    "        'weight_decay': 0.0,                   # weight decay\n",
    "        'device_name': 'cuda:0'}    \n",
    "\n",
    "\n",
    "num_WL_Steps = 101\n",
    "\n",
    "WL = Y[:,9*num_WL_Steps:10*num_WL_Steps]\n",
    "WSA = Y[:,8*num_WL_Steps:9*num_WL_Steps]\n",
    "\n",
    "#Y_set = Y[:,8*num_WL_Steps:9*num_WL_Steps]\n",
    "idx = np.where(np.isnan(WL))\n",
    "#print(idx)\n",
    "\n",
    "WL[idx] = 1.0 #fix nan to dummy value\n",
    "\n",
    "idx = np.where(np.isnan(WSA))\n",
    "#print(idx)\n",
    "\n",
    "WSA[idx] = -5.0 #fix nan to dummy value\n",
    "\n",
    "\n",
    "REG = Drag_Regressor_Training_Env(Reg_Dict, DesVec, Cw, WL, WSA)\n",
    "\n",
    "model_size = 0\n",
    "for p in REG.model.parameters():\n",
    "        model_size += p.numel()\n",
    "\n",
    "print('Model size: ', model_size)\n",
    "\n",
    "REG.run_train_regressors_loop(batches_per_epoch=8, subsample_per_batch = 8)\n",
    "\n",
    "REG.Save_model('./TrainedModels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log scale MAEP: 1.4282303862273693%\n",
      "Scaled Ct MAEP: 6.629853695631027%\n",
      "R2 score of Scaled Ct Prediction: 0.9937638501995272\n",
      "R2 score of Scaled Rt Prediction: 0.9937638501995272\n",
      "Scaled Rt MAEP: 6.629852816703814%\n"
     ]
    }
   ],
   "source": [
    "REG.model.eval()\n",
    "\n",
    "sample_size = 100000\n",
    "\n",
    "\n",
    "A = np.random.randint(0,REG.data_length,sample_size)\n",
    "x_eval = torch.tensor(REG.X[A]).float().to(REG.device)\n",
    "\n",
    "x_eval,Y_calc = REG.batch_CT(x_eval,A,sample_size)\n",
    "\n",
    "Y_calc = Y_calc.to(torch.device('cpu')).detach().numpy()\n",
    "\n",
    "Y_pred = REG.model(x_eval)\n",
    "Y_pred = Y_pred.to(torch.device('cpu')).detach().numpy() \n",
    "\n",
    "\n",
    "\n",
    "#MAEP = np.mean(np.abs(np.power(10,Y_calc)-np.power(10,Y_pred)/np.power(10,Y_calc)))\n",
    "MAEP = np.mean(np.abs(Y_calc-Y_pred)/np.abs(Y_calc))\n",
    "print('Log scale MAEP: ' + str(MAEP*100.0) + '%')\n",
    "\n",
    "\n",
    "Y_scaled_calc = 10**Y_calc\n",
    "Y_scaled_pred = 10**Y_pred  \n",
    "\n",
    "MAEP_scaled = np.mean(np.abs(Y_scaled_calc-Y_scaled_pred)/np.abs(Y_scaled_calc))\n",
    "print('Scaled Ct MAEP: ' + str(MAEP_scaled*100.0) + '%')\n",
    "Rsq = r2_score(Y_scaled_calc, Y_scaled_pred)\n",
    "\n",
    "print(\"R2 score of Scaled Ct Prediction: \" + str(Rsq))\n",
    "\n",
    "\n",
    "# Calculate Rt\n",
    "\n",
    "x_eval = x_eval.to(torch.device('cpu')).detach().numpy()\n",
    "\n",
    "LOA = 10**x_eval[:,-1]\n",
    "t = (x_eval[:,-3])\n",
    "\n",
    "WL = np.array([HP.interp(REG.WL[A[i]],REG.T_vec,t[i]) for i in range(0,len(t))]) #Non-dimensionalized Waterline Length    \n",
    "\n",
    "\n",
    "U = x_eval[:,-2]*np.sqrt(9.81*LOA*WL)\n",
    "\n",
    "Rt_Calc = 0.5*rho*(U**2.0) * (LOA**2.0) * Y_scaled_calc[:,0]\n",
    "\n",
    "\n",
    "Rt_Pred = 0.5*rho*(U**2.0) * (LOA**2.0) * Y_scaled_pred[:,0]\n",
    "\n",
    "\n",
    "\n",
    "Rsq = r2_score(Y_scaled_calc, Y_scaled_pred)\n",
    "\n",
    "print(\"R2 score of Scaled Rt Prediction: \" + str(Rsq))\n",
    "MAEP_scaled_Rt = np.mean(np.abs(Rt_Calc-Rt_Pred)/np.abs(Rt_Calc))\n",
    "print('Scaled Rt MAEP: ' + str(MAEP_scaled_Rt*100.0) + '%')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
